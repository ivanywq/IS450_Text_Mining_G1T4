{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Extraction - Solution 4: Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6039603960396039\n",
      "Recall: 0.6039603960396039\n",
      "F1 Score: 0.6039603960396039\n",
      "Average Cosine Similarity: 0.9954271045061621\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Function to preprocess and normalize sentences\n",
    "def preprocess_and_normalize_sentence(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = re.sub(r\"\\b(\\w+)\\s's\\b\", r\"\\1's\", sentence)\n",
    "        sentence = sentence.lower()\n",
    "    else:\n",
    "        sentence = str(sentence)\n",
    "    return sentence\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('news_cleaned_no_spaces.csv', encoding='latin1')\n",
    "df = df[:101]\n",
    "\n",
    "# Assume df['gold_truth'] contains your event sentences\n",
    "event_sentences = df['news_text'].tolist()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_sentences, test_sentences = train_test_split(event_sentences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare training data\n",
    "train_documents = [TaggedDocument(words=word_tokenize(str(doc).lower()), tags=[i]) for i, doc in enumerate(train_sentences) if doc == doc]\n",
    "\n",
    "# Prepare training data\n",
    "documents = [TaggedDocument(words=word_tokenize(str(doc).lower()), tags=[i]) for i, doc in enumerate(event_sentences) if doc == doc]\n",
    "\n",
    "# Train a Doc2Vec model\n",
    "model = Doc2Vec(documents, vector_size=100, window=5, min_count=2, workers=4, epochs=20, dm=1)\n",
    "\n",
    "# Create a DataFrame that's a copy of the original\n",
    "predicted_df = df.copy()\n",
    "\n",
    "# Add a new column 'output' initialized with NaN\n",
    "predicted_df['output'] = np.nan\n",
    "# Assume df['news_text'] contains the text from which you want to extract event sentences\n",
    "news_text = df['news_text'].tolist()\n",
    "\n",
    "# Prepare a list to store the cosine similarities\n",
    "similarities = []\n",
    "\n",
    "# Initialize counters\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "# Assume golden_truth is a list of the actual events\n",
    "golden_truth = df['gold_truth'].tolist()\n",
    "\n",
    "# Preprocess and normalize the golden truth\n",
    "normalized_golden_truth = [preprocess_and_normalize_sentence(sentence) for sentence in golden_truth]\n",
    "\n",
    "# Iterate over the event sentences\n",
    "for idx, text in enumerate(news_text):\n",
    "    # Check if text is not NaN\n",
    "    if text == text:\n",
    "        # Infer a vector for the sentence\n",
    "        vector = model.infer_vector(word_tokenize(str(text).lower()))\n",
    "        \n",
    "        # Find the most similar sentences in your event sentences\n",
    "        similar_sentences = model.dv.most_similar([vector], topn=1)\n",
    "        \n",
    "        # Store the most similar sentence (the prediction) in the 'output' column\n",
    "        predicted_df.loc[idx, 'output'] = event_sentences[similar_sentences[0][0]]\n",
    "\n",
    "        # Calculate the cosine similarity between the vector of the predicted sentence and the vector of the actual sentence\n",
    "        predicted_vector = model.infer_vector(word_tokenize(predicted_df.loc[idx, 'output'].lower()))\n",
    "        similarity = cosine_similarity([vector], [predicted_vector])\n",
    "        \n",
    "        # Add the cosine similarity to the list\n",
    "        similarities.append(similarity[0][0])\n",
    "\n",
    "        # Preprocess and normalize the predicted sentence\n",
    "        normalized_output = preprocess_and_normalize_sentence(predicted_df.loc[idx, 'output'])\n",
    "\n",
    "        # Check if the normalized predicted sentence is in the normalized golden truth\n",
    "        if any(normalized_truth in normalized_output for normalized_truth in normalized_golden_truth):\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "\n",
    "FN = len(normalized_golden_truth) - TP\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "average_similarity = sum(similarities) / len(similarities)\n",
    "\n",
    "print(f'Average Cosine Similarity: {average_similarity}')\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save to CSV\n",
    "predicted_df.to_csv(f'predicted_sentences_doc2vec{timestamp}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
