{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>time_published</th>\n",
       "      <th>authors</th>\n",
       "      <th>summary</th>\n",
       "      <th>banner_image</th>\n",
       "      <th>source</th>\n",
       "      <th>category_within_source</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>topics</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ticker_sentiment_score</th>\n",
       "      <th>ticker_sentiment_label</th>\n",
       "      <th>news_text</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>keywords</th>\n",
       "      <th>company_name</th>\n",
       "      <th>relevant_sentences</th>\n",
       "      <th>processed_relevant_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA: Will These Semiconductor Stocks Deliver ...</td>\n",
       "      <td>https://stocknews.com/news/nvda-tsm-avgo-csco-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Despite macroeconomic challenges, the semicond...</td>\n",
       "      <td>https://stocknews.com/wp-content/uploads/2022/...</td>\n",
       "      <td>Stocknews.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stocknews.com</td>\n",
       "      <td>[{'topic': 'Financial Markets', 'relevance_sco...</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.197061</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>Despite macroeconomic challenges, the semicond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['csco', 'cisco', 'systems']</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>['On February 6, 2024, NVDA partnered together...</td>\n",
       "      <td>['On February 6, 2024, NVDA partnered together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Cheap Tech Stocks to Buy Right Now</td>\n",
       "      <td>https://www.fool.com/investing/2024/02/12/3-ch...</td>\n",
       "      <td>2/12/24 00:00</td>\n",
       "      <td>Leo Sun</td>\n",
       "      <td>IBM, AT&amp;T, and Cisco are all attractive safe h...</td>\n",
       "      <td>https://g.foolcdn.com/image/?url=https%3A%2F%2...</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.fool.com</td>\n",
       "      <td>[{'topic': 'Earnings', 'relevance_score': '0.9...</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.046564</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Many tech stocks soared over the past year as ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['csco', 'cisco', 'systems']</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>['I believe three underappreciated blue chip s...</td>\n",
       "      <td>['I believe three underappreciated blue chip s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia's Valuation Sparks Reddit Debate: Echoe...</td>\n",
       "      <td>https://www.benzinga.com/trading-ideas/long-id...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surbhi Jain</td>\n",
       "      <td>The technology sector has always been a hot to...</td>\n",
       "      <td>https://cdn.benzinga.com/files/images/story/20...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Trading</td>\n",
       "      <td>www.benzinga.com</td>\n",
       "      <td>[{'topic': 'Financial Markets', 'relevance_sco...</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.468392</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>The technology sector has always been a hot to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['csco', 'cisco', 'systems']</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>['Redditor u/waterlimes sparked a conversation...</td>\n",
       "      <td>['Redditor u/waterlimes sparked a conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spotlight on Cisco Systems: Analyzing the Surg...</td>\n",
       "      <td>https://www.benzinga.com/insights/options/24/0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>Deep-pocketed investors have adopted a bullish...</td>\n",
       "      <td>https://cdn.benzinga.com/files/images/story/20...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Markets</td>\n",
       "      <td>www.benzinga.com</td>\n",
       "      <td>[{'topic': 'Earnings', 'relevance_score': '0.1...</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.412413</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Deep-pocketed investors have adopted a bullish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['csco', 'cisco', 'systems']</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>[\"Deep-pocketed investors have adopted a bulli...</td>\n",
       "      <td>[\"Deep-pocketed investors have adopted a bulli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If You Like Nvidia, Then You Will Love These 2...</td>\n",
       "      <td>https://www.fool.com/investing/2024/02/11/if-y...</td>\n",
       "      <td>2/11/24 00:00</td>\n",
       "      <td>Daniel Foelber, Scott Levine, Lee Samaha</td>\n",
       "      <td>These companies have clearly defined runways f...</td>\n",
       "      <td>https://g.foolcdn.com/image/?url=https%3A%2F%2...</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.fool.com</td>\n",
       "      <td>[{'topic': 'Financial Markets', 'relevance_sco...</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.078029</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Nvidia (NVDA -5.55%) could be about to do the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['csco', 'cisco', 'systems']</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>['This week, for example, it announced a partn...</td>\n",
       "      <td>['This week, for example, it announced a partn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  NVDA: Will These Semiconductor Stocks Deliver ...   \n",
       "1               3 Cheap Tech Stocks to Buy Right Now   \n",
       "2  Nvidia's Valuation Sparks Reddit Debate: Echoe...   \n",
       "3  Spotlight on Cisco Systems: Analyzing the Surg...   \n",
       "4  If You Like Nvidia, Then You Will Love These 2...   \n",
       "\n",
       "                                                 url time_published  \\\n",
       "0  https://stocknews.com/news/nvda-tsm-avgo-csco-...            NaN   \n",
       "1  https://www.fool.com/investing/2024/02/12/3-ch...  2/12/24 00:00   \n",
       "2  https://www.benzinga.com/trading-ideas/long-id...            NaN   \n",
       "3  https://www.benzinga.com/insights/options/24/0...            NaN   \n",
       "4  https://www.fool.com/investing/2024/02/11/if-y...  2/11/24 00:00   \n",
       "\n",
       "                                    authors  \\\n",
       "0                                       NaN   \n",
       "1                                   Leo Sun   \n",
       "2                               Surbhi Jain   \n",
       "3                         Benzinga Insights   \n",
       "4  Daniel Foelber, Scott Levine, Lee Samaha   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Despite macroeconomic challenges, the semicond...   \n",
       "1  IBM, AT&T, and Cisco are all attractive safe h...   \n",
       "2  The technology sector has always been a hot to...   \n",
       "3  Deep-pocketed investors have adopted a bullish...   \n",
       "4  These companies have clearly defined runways f...   \n",
       "\n",
       "                                        banner_image         source  \\\n",
       "0  https://stocknews.com/wp-content/uploads/2022/...  Stocknews.com   \n",
       "1  https://g.foolcdn.com/image/?url=https%3A%2F%2...    Motley Fool   \n",
       "2  https://cdn.benzinga.com/files/images/story/20...       Benzinga   \n",
       "3  https://cdn.benzinga.com/files/images/story/20...       Benzinga   \n",
       "4  https://g.foolcdn.com/image/?url=https%3A%2F%2...    Motley Fool   \n",
       "\n",
       "  category_within_source     source_domain  \\\n",
       "0                    NaN     stocknews.com   \n",
       "1                    NaN      www.fool.com   \n",
       "2                Trading  www.benzinga.com   \n",
       "3                Markets  www.benzinga.com   \n",
       "4                    NaN      www.fool.com   \n",
       "\n",
       "                                              topics ticker  \\\n",
       "0  [{'topic': 'Financial Markets', 'relevance_sco...   CSCO   \n",
       "1  [{'topic': 'Earnings', 'relevance_score': '0.9...   CSCO   \n",
       "2  [{'topic': 'Financial Markets', 'relevance_sco...   CSCO   \n",
       "3  [{'topic': 'Earnings', 'relevance_score': '0.1...   CSCO   \n",
       "4  [{'topic': 'Financial Markets', 'relevance_sco...   CSCO   \n",
       "\n",
       "  ticker_sentiment_score ticker_sentiment_label  \\\n",
       "0               0.197061       Somewhat-Bullish   \n",
       "1               0.046564                Neutral   \n",
       "2               0.468392                Bullish   \n",
       "3               0.412413                Bullish   \n",
       "4               0.078029                Neutral   \n",
       "\n",
       "                                           news_text Unnamed: 14  \\\n",
       "0  Despite macroeconomic challenges, the semicond...         NaN   \n",
       "1  Many tech stocks soared over the past year as ...         NaN   \n",
       "2  The technology sector has always been a hot to...         NaN   \n",
       "3  Deep-pocketed investors have adopted a bullish...         NaN   \n",
       "4  Nvidia (NVDA -5.55%) could be about to do the ...         NaN   \n",
       "\n",
       "                       keywords         company_name  \\\n",
       "0  ['csco', 'cisco', 'systems']  Cisco Systems, Inc.   \n",
       "1  ['csco', 'cisco', 'systems']  Cisco Systems, Inc.   \n",
       "2  ['csco', 'cisco', 'systems']  Cisco Systems, Inc.   \n",
       "3  ['csco', 'cisco', 'systems']  Cisco Systems, Inc.   \n",
       "4  ['csco', 'cisco', 'systems']  Cisco Systems, Inc.   \n",
       "\n",
       "                                  relevant_sentences  \\\n",
       "0  ['On February 6, 2024, NVDA partnered together...   \n",
       "1  ['I believe three underappreciated blue chip s...   \n",
       "2  ['Redditor u/waterlimes sparked a conversation...   \n",
       "3  [\"Deep-pocketed investors have adopted a bulli...   \n",
       "4  ['This week, for example, it announced a partn...   \n",
       "\n",
       "                        processed_relevant_sentences  \n",
       "0  ['On February 6, 2024, NVDA partnered together...  \n",
       "1  ['I believe three underappreciated blue chip s...  \n",
       "2  ['Redditor u/waterlimes sparked a conversation...  \n",
       "3  [\"Deep-pocketed investors have adopted a bulli...  \n",
       "4  ['This week, for example, it announced a partn...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv('data_with_relevant_sentences.csv')\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                               0\n",
       "url                                 0\n",
       "time_published                  11589\n",
       "authors                          3418\n",
       "summary                             0\n",
       "banner_image                     2226\n",
       "source                              0\n",
       "category_within_source          14478\n",
       "source_domain                       0\n",
       "topics                              0\n",
       "ticker                              0\n",
       "ticker_sentiment_score              0\n",
       "ticker_sentiment_label              0\n",
       "news_text                           0\n",
       "Unnamed: 14                     26437\n",
       "keywords                            0\n",
       "company_name                       25\n",
       "relevant_sentences                  0\n",
       "processed_relevant_sentences        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing relevant (for sentiment analysis) columns that are NA\n",
    "news_df = news_df.dropna(subset=['ticker','relevant_sentences'])\n",
    "news_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/adam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [february, nvda, partnered, together, cisco, c...\n",
       "1    [believe, three, underappreciated, blue, chip,...\n",
       "2    [sparked, conversation, drawing, parallel, nvi...\n",
       "3    [investor, adopted, bullish, approach, towards...\n",
       "4    [week, example, announced, partnership, cisco,...\n",
       "Name: relevant_sentences, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')  # Download Wordnet for lemmatization\n",
    "\n",
    "# Initialize a WordNetLemmatizer for lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(text)\n",
    "    # Convert to lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Remove punctuation and numbers\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    # Perform lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Apply the preprocessing to the 'relevant_sentences' column\n",
    "news_df['relevant_sentences'] = news_df['relevant_sentences'].apply(preprocess_text)\n",
    "\n",
    "news_df['relevant_sentences'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with no tokens\n",
    "news_df = news_df[news_df['relevant_sentences'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker_sentiment_label\n",
      "Neutral                                                                                                                          12727\n",
      "Somewhat-Bullish                                                                                                                  6737\n",
      "Bullish                                                                                                                           3056\n",
      "Somewhat-Bearish                                                                                                                   606\n",
      "Bearish                                                                                                                            146\n",
      " respectively (December 2022 - expense of $214 and a recovery of $145). These amounts are included in direct cost of revenues       12\n",
      " net other consisted of $2.2 million of net other                                                                                    1\n",
      " consisted of $1.8 million of net other                                                                                              1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "golden_sentiment\n",
       "Neutral    12727\n",
       "Bullish     9793\n",
       "Bearish      752\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(news_df['ticker_sentiment_label'].value_counts())\n",
    "\n",
    "# Define the valid sentiment labels\n",
    "valid_labels = ['Bullish', 'Bearish', 'Neutral', 'Somewhat-Bullish', 'Somewhat-Bearish']\n",
    "\n",
    "# Keep only the rows where 'ticker_sentiment_label' is in valid_labels\n",
    "news_df = news_df[news_df['ticker_sentiment_label'].isin(valid_labels)]\n",
    "\n",
    "def simplify_sentiment(label):\n",
    "    if 'Bullish' in label:\n",
    "        return 'Bullish'\n",
    "    elif 'Bearish' in label:\n",
    "        return 'Bearish'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "news_df['golden_sentiment'] = news_df['ticker_sentiment_label'].apply(simplify_sentiment)\n",
    "\n",
    "news_df['golden_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golden_sentiment\n",
      "Bearish    9793\n",
      "Bullish    9793\n",
      "Neutral    9793\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate the classes\n",
    "df_bearish = news_df[news_df.golden_sentiment == 'Bearish']\n",
    "df_bullish = news_df[news_df.golden_sentiment == 'Bullish']\n",
    "df_neutral = news_df[news_df.golden_sentiment == 'Neutral']\n",
    "\n",
    "# Find the number of samples in the middle class\n",
    "n_samples = df_bullish.shape[0]  # Assuming 'Bullish' has a count in between 'Bearish' and 'Neutral'\n",
    "\n",
    "# Upsample 'Bearish' class and downsample 'Neutral' class to match the number of samples in 'Bullish' class\n",
    "df_bearish_upsampled = resample(df_bearish, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_neutral_downsampled = resample(df_neutral, replace=False, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Combine the resampled classes\n",
    "df_resampled = pd.concat([df_bearish_upsampled, df_bullish, df_neutral_downsampled])\n",
    "\n",
    "# Check the new class counts\n",
    "print(df_resampled.golden_sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.79      0.91      0.85      1933\n",
      "     Bullish       0.65      0.74      0.69      2005\n",
      "     Neutral       0.71      0.49      0.58      1938\n",
      "\n",
      "    accuracy                           0.72      5876\n",
      "   macro avg       0.72      0.72      0.71      5876\n",
      "weighted avg       0.71      0.72      0.71      5876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert the list of tokens back into a string\n",
    "df_resampled['processed_text'] = df_resampled['relevant_sentences'].apply(' '.join)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_resampled['processed_text'], df_resampled['golden_sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize a MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = nb.predict(X_test_vect)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
